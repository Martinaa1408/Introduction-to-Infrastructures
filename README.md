## BDP1_2025 - Introduction to Big Data Processing Infrastructures

**Welcome to the official repository of the BDP1 2025 course!**  
This repository contains educational resources, lecture summaries, quizzes, and exam preparation material for the *Introduction to Big Data Processing Infrastructures* course, part of the MSc in Bioinformatics.

---

## Abstract and Information

The course will provide basic concepts of Computing Infrastructures for processing Big Data and for running scientific applications. In particular it will focus on the Infrastructure-as-a-Service Cloud paradigm. 
The course will provide an introduction to Big Data and how they are related to scientific  applications. 
It will continue with a description of the building blocks of modern Data Centers and how they are abstracted by the Cloud computing models. 
A real-life computational challenge will be given and students will create (during the course) a Cloud-based computing model to solve this challenge. 
Access to a limited set of Cloud resources and services will be granted to students in order to complete the exercises.  
Containers and in particular Docker Containers will be introduced as for the concept of High Performance Computing (HPC). 
Notions about the emerging “Fog” and “Edge” computing paradigms and how they are linked to Cloud infrastructures will conclude the course.

---

## RECAP

#### Big Data Chapter -->

`Big Data (massive, high-volume)`
→ Massive volume of data that exceeds the capacity of traditional tools to manage and analyze.

`5Vs (diverse, high-speed, uncertain, valuable)`
→ Volume, Velocity, Variety, Veracity, Value – the core characteristics of Big Data.

`Volume (large)`
→ Total amount of data generated and stored.

`Velocity (fast)`
→ The speed at which data is produced, transmitted, and processed.

`Variety (heterogeneous)`
→ Different types and formats of data: structured, semi-structured, unstructured.

`Veracity (noisy, unreliable)`
→ The trustworthiness and quality of the data (presence of noise, inconsistency, uncertainty).

`Value (meaningful, business-driven)`
→ The useful insight or benefit extracted from the data.

#### Hardware Terms – PC Components -->

`CPU (fast, parallel)`
→ Central Processing Unit. Executes instructions of programs. Can have multiple cores for parallelism.

`RAM (volatile, temporary)`
→ Random Access Memory. Temporarily holds data for currently running programs.

`SSD (persistent, fast)`
→ Solid State Drive. Fast, non-volatile storage with no moving parts.

`HDD (persistent, slow)`
→ Hard Disk Drive. Traditional magnetic disk storage, slower but cheaper.

`GPU (parallel, high-throughput)`
→ Graphics Processing Unit. Optimized for massively parallel processing (used in ML, AI, simulation).

`Power Supply (critical, stable)`
→ Converts AC power to low-voltage DC power used by internal components.

`I/O Devices (external, interactive)`
→ Input/output peripherals such as keyboard, mouse, display, storage drives.














---

## SLIDE

- [🔎Google Drive](https://drive.google.com/file/d/1wzA1xtHW14hh-PvJJcho1k4J8ZIhmPxt/view?usp=sharing)
  
---

## Official Course Repository

For additional materials, examples, and practical exercises, visit the instructor's GitHub repository:  

👉 [https://github.com/dcesini/BDP1_2025](https://github.com/dcesini/BDP1_2025)

Other repository related to the course of Infrastructures for Big Data Processing:

👉 [https://github.com/alexcos78/bdp2](https://github.com/alexcos78/bdp2)

---


## Purpose

This PDF serves as a **comprehensive study guide** for the entire BDP1 course, bringing together all theoretical and practical elements into a single, well-structured document.
