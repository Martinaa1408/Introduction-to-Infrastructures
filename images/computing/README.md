# Computing
This folder contains visual explanations of computing job types and resource allocation strategies used in High Throughput Computing (HTC) and High Performance Computing (HPC) environments.

`job-types.png`

This diagram illustrates various types of jobs submitted to computing infrastructures:

Single batch job: An isolated task with no dependencies.

DAG workflow: A Directed Acyclic Graph structure where tasks are executed based on logical dependencies.

Collection: A group of independent jobs submitted together.

Parametric: A set of jobs generated by varying parameters over a template.

Parallel: Jobs that must run simultaneously across multiple cores or machines.

Connection: This image links to the concept of workflow structures in `HTC-HPC-workflow.png` (from the Job scheduling section), as it outlines how job logic is organized.

`resources.png`

This image shows a resource sharing policy over time between two user groups (A and B):

Both groups are initially allocated 50% of the computing resources.

Group A temporarily stops, and Group B uses excess capacity.

When Group A returns, it reclaims its share.

Compensation mechanisms ensure fairness over time.

Connection: This image connects with `queue.png` (from the Job scheduling section) and represents the practical implementation of fair-sharing policies and backfilling used by job queues in batch systems.

`DAS-NAS-SAN.png`

This image compares three common storage architectures:

-DAS (Direct-Attached Storage) – Left (Red):

Storage is directly connected to a single server.
Fast and simple, but not shareable among multiple servers.
Example: External hard drive or internal disk array.

-NAS (Network-Attached Storage) – Middle (Blue):

Storage is connected over a LAN and shared by multiple servers.
Managed through Ethernet switches.
Suitable for file-level access (e.g., home/office file servers).

-SAN (Storage Area Network) – Right (Yellow):

High-performance block-level storage connected via fiber channel switches.
Designed for large data centers with high I/O demands.
More complex and expensive, but scalable and fast.


Each architecture offers different trade-offs in performance, cost, and scalability.



